#summary More detailed description of the first ArrowsSpace prototype

This page describes the first ArrowsSpace prototype.

== Architecture overview ==

The ArrowsSpace software prototype consists in a thread-safe library (EntrelacsLibrary) providing operators to compose, root, and browse arrows in a single file on the host file system.

An HTTP/REST server is also planed on top of this library so that local or remote clients may simultaneously access a same AS.

== Complex objects support ==

The prototype will handle several types of complex objects in addition with regular arrows (ie. references pairs). That is:
  * _blobs_, ie. *large* binary strings,
  * _tags_, ie. *short* binary strings,
  * _tuple_, ie. an ordered set of n (n >= 1) arrows
  * _small_, a piece of raw data which is small enough to fit in an arrow storage cell.

Reminder: Despite _blobs_, _tags_ and _smalls_ are raw binary objects, they are still treated like their equivalent arrow constructs, namely _entrelacs_ (discrete reentrant structures of arrows).

== Mass storage usage ==

The persistence file is operated as a bank of storage units called _cells_.

One cell :
  * is identified and located by a cell address,
  * may contain a pair of addresses and/or a couple of other things.

A regular arrow being a pair of arrows, it is consequently stored as a pair of addresses into a single cell.

Raw data (blobs and tags) are also stored into cells like regular arrows. They are taken into slices and stored in several cells separated by a predictable offset.

Note that contrary to tags, blobs may be very long, so one stores its unique hashed signature before its data in order to accelerate existing singleton identification.

Note data strings must not be mixed up with existing data. One needs to jump over conflicting cells up to the next valid slice of string. Some bits are reserved to store an offset multiplier on this purpose (namely _jump_).

== Open Addressing ==

One relays on OpenAddressing to manage conflicts within the storage space.
  * When an object definition can't be stored at its expected location because of some already present content, one repeatedly shifts the storage location by a variable but predictable offset until one finds a free cell.
  * When one looks for something, one starts a search from the object expected location, and one probes for the object until one reaches the object (hit!) or an empty cell (miss!).

== Little thumbling algorithm ==

An issue with Open Addressing is that one can't fully empty a cell without breaking one or several sequences of busy cells that one must go through to find existing content.

A solution consists in incrementing a dedicated "more" counter on every cell visited from the default location up to its actual location. These counters are comparably decremented upon object removal. With this solution, probing doesn't fail until one gets a empty cell with a "more" counter set to zero.

== Connectivity ==

For each newly assimilated arrow _a_, one also attaches 2 back-references to its ends (head and tail) definition, that is:
  * _a_ reference in a cell "after" _a.tail_ definition,
  * _a_ reference in a cell "before" _a.head_ definition.

These back-references form an index to browse all children arrows of a given arrow.

See hereafter a better meaning of "after" and "before" expressions.

== Overview of stored data ==

For each arrow, one needs to store:
  * its definition, that is
     * two arrow references for a pair
     * a C string preceded by its (short) checksum for a tag
     * a binary string preceded by its cryptographic signature for a blob.
  * its root flag (one mutable bit)
  * its connectivity data, that is:
     * a list of back-references to incoming and outgoing children
     * a total children counter (TBC)

== Cell categories ==

As different kinds of data may be found in a cell, one needs to identify a cell content by a few bit length value named "category" hereafter.
  * A: Arrow
  * I: Small (Integer)
  * S: Tag (String)
  * B: Blob
  * T: Tuple
  * R: Remaining
  * L: Last remaining
  * X: Redirection

R/L cells are used to store
 * either the continuation of a B, S, or T definition
 * or children list.

X contains addresses referring cells moved elsewhere because of extreme data cluttering.

== Hashing definitions ==

One makes use of an hash function to compute an arrow's _open address_ out of its definition.

The hash function is chosen after the type of arrow:
  * For a _blob_, one uses a cryptographic unambiguous hash function (SHA).
  * For a _tag_, one uses a simpler checksum. When comparing an assimilated tag with a potential copy, one must check every char of the string.
  * For a regular arrow, one hashes the tail and head's respective hash codes. The hash function might be commutative (ToBeConfirmed) so that one may deduce an arrow hash code by combining its furthest ancestor hash codes rather than fetching every intermediate parent arrows.

The overall hash function _h_ consequently verifies :
  * _h_(Pair) = some_math_of(h(tail(Pair)), h(head(Pair))) 
  * _h_(Tag) = checksum(Tag)
  * _h_(Blob) = sha(Blob) (or any cryptographic hash function).

== Double Hashing to move apart related cells ==

One could decide to reserve and fill up a set of consecutive cells to store several slices of a same arrow definition (blob, tag...). But this naive approach would lead to _data cluttering_.

A better approach consists in separating data slices by a variable offset. This offset has to be different for each arrow in order to minimize collisions. This particular strategy is called DoubleHashing.

Suggestion: truncating a bigger hash modulo 2 twin prim numbers. H % p1 for the open address, H % p2 for the separation offset.


== Coalesced Hashing ==

Complex object (tuples, blobs, tags) definitions can't fit in a single cell. One takes them into slices and dispatches them into many cells separated by a predictable offset.

But there's a risk some cells are already used. One must jump over such busy cells when storing and retrieving data.

Every cell consequently hosts a "jump factor" to jump over colliding cells. This strategy is vaguely related to CoalescedHashing.

The jump factor doesn't need to be a fully qualified cell address. It only counts the number of shift until the next relevant cell.

The jump factor max value is low, but so is the probability of many repeated *consecutive* collisions. In case of 

There are 3 offset to shift from a given location functions used for probing, back-refs dispatching, string slice dispatching) to avoid cluttering even more.

Some misc candidate offsets:
 * offset for probing = h % p2 (p2 = second twin prim number)
 * offset between string slices = swapBytes(h) % p2
 * offset between back-refs = neg(h) % p2

Still studied: A cell could store more than one of addresses. Collocation for small object managed by flag bits.

== Arrow typical footprint ==

Finally, here is the ideal (no conflict) footprint of an arrow assimilated as _i_ (its ID). _i_ goes out a _tail_ arrow and comes into an _head_ arrow (two other ID). _i_ is also referred by several incoming or outgoing children arrows.

== RAM Cache ==

When needed, arrows climb up to a level 1 (RAM) memory device. This memory is used as a fine-grained cache of level 0 cells. 
See ArrowsCache for further details.

== Garbage Collector ==

The AS features a garbage collection process which spares rooted arrows and all their "ancestors" and gets back resources used by no more rooted nor referred arrows.

On this purpose, a reference counter is attached to every arrow. This counter is incremented each time a new arrow is incoming/outgoing  from/to the given arrow. It is decremented when such a child arrow is deleted by the garbage collector. When both an arrow is non-rooted and has 0 children, one can recycle its storage resources.

The GC proceeds to-be-deleted arrows in an incremental way. Its job is dispatched on many transactions to avoid CPU overhead. Since arrows are not deleted immediately, they may be saved from deletion by being rooted or linked back. An additional check of deletion criteria is performed just before the actual deletion.

== more ==
=== candidate hash functions so far ===
For practical reasons, the hash function should be commutative on structure of pairs. To be done.

     * key hash = f(tail, head) = ((head << 24) & tail) % P0
     * drone hash = g(tail, head) = ((head << 24) & tail) % P1
        * where P0 and P1 are twin prims near mem0 size 2^24
     * BLOB hash = truncated SHA-2
     * TAG hash = simpler checksum, like in http://www.cse.yorku.ca/~oz/hash.html

== even more ==

cf. InProgress